{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e67525ec-947c-44d0-9a5a-20999efc234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3130114e-22be-4ad4-a221-4c7e4a74e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(user_id, name):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "    save_path = f\"dataset/{name}_{user_id}\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    while count < 50:  # Capture 50 samples per user\n",
    "        ret, frame = cap.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            face = gray[y:y+h, x:x+w]\n",
    "            file_path = os.path.join(save_path, f\"{count}.jpg\")\n",
    "            cv2.imwrite(file_path, face)\n",
    "            count += 1\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        cv2.imshow(\"Capturing Face\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q') or count >= 50:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88662e84-4d2a-4aa0-938a-0986b73540db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    face_data = []\n",
    "    labels = []\n",
    "    label_map = {}\n",
    "\n",
    "    dataset_path = \"dataset\"\n",
    "    label_id = 0\n",
    "\n",
    "    for folder in os.listdir(dataset_path):\n",
    "        folder_path = os.path.join(dataset_path, folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue  # Skip files that are not directories\n",
    "        \n",
    "        for image_name in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            print(f\"Loading image from {image_path}\")  # Check the path\n",
    "            \n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Error: Image not found at {image_path}\")\n",
    "                continue  # Skip invalid images\n",
    "            \n",
    "            face_data.append(np.array(image, dtype=\"uint8\"))\n",
    "            labels.append(label_id)\n",
    "        \n",
    "        label_map[label_id] = folder\n",
    "        label_id += 1\n",
    "\n",
    "    recognizer.train(face_data, np.array(labels))\n",
    "    recognizer.save(\"face_recognizer.yml\")\n",
    "    with open(\"label_map.npy\", \"wb\") as f:\n",
    "        np.save(f, label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ecc6c64-d240-493f-b89e-cf989d8c5821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_attendance(name):\n",
    "    attendance_file = \"attendance.csv\"\n",
    "    now = datetime.now()\n",
    "    time = now.strftime(\"%H:%M:%S\")\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    attendance_data = []\n",
    "\n",
    "    if os.path.exists(attendance_file):\n",
    "        attendance_data = pd.read_csv(attendance_file).to_dict(\"records\")\n",
    "    \n",
    "    # Avoid duplicate marking\n",
    "    for entry in attendance_data:\n",
    "        if entry[\"Name\"] == name and entry[\"Date\"] == date:\n",
    "            return\n",
    "\n",
    "    attendance_data.append({\"Name\": name, \"Date\": date, \"Time\": time})\n",
    "    pd.DataFrame(attendance_data).to_csv(attendance_file, index=False)\n",
    "\n",
    "def recognize_and_mark():\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.read(\"face_recognizer.yml\")\n",
    "\n",
    "    with open(\"label_map.npy\", \"rb\") as f:\n",
    "        label_map = np.load(f, allow_pickle=True).item()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face = gray[y:y+h, x:x+w]\n",
    "            label, confidence = recognizer.predict(face)\n",
    "            if confidence < 50:  # Confidence threshold\n",
    "                name = label_map[label]\n",
    "                mark_attendance(name)\n",
    "                cv2.putText(frame, name, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Unknown\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Face Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20df470e-7dbe-4e5f-818b-baaec0e3acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image loaded successfully\n"
     ]
    }
   ],
   "source": [
    "test_image_path = \"dataset/Jaideep_001/0.jpg\"\n",
    "test_image = cv2.imread(test_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "if test_image is None:\n",
    "    print(\"Failed to load test image\")\n",
    "else:\n",
    "    print(\"Test image loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03a838ee-b119-4687-bf62-c988b39ed0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image from dataset\\Jaideep_001\\.ipynb_checkpoints\n",
      "Error: Image not found at dataset\\Jaideep_001\\.ipynb_checkpoints\n",
      "Loading image from dataset\\Jaideep_001\\0.jpg\n",
      "Loading image from dataset\\Jaideep_001\\1.jpg\n",
      "Loading image from dataset\\Jaideep_001\\10.jpg\n",
      "Loading image from dataset\\Jaideep_001\\11.jpg\n",
      "Loading image from dataset\\Jaideep_001\\12.jpg\n",
      "Loading image from dataset\\Jaideep_001\\13.jpg\n",
      "Loading image from dataset\\Jaideep_001\\14.jpg\n",
      "Loading image from dataset\\Jaideep_001\\15.jpg\n",
      "Loading image from dataset\\Jaideep_001\\16.jpg\n",
      "Loading image from dataset\\Jaideep_001\\17.jpg\n",
      "Loading image from dataset\\Jaideep_001\\18.jpg\n",
      "Loading image from dataset\\Jaideep_001\\19.jpg\n",
      "Loading image from dataset\\Jaideep_001\\2.jpg\n",
      "Loading image from dataset\\Jaideep_001\\20.jpg\n",
      "Loading image from dataset\\Jaideep_001\\21.jpg\n",
      "Loading image from dataset\\Jaideep_001\\22.jpg\n",
      "Loading image from dataset\\Jaideep_001\\23.jpg\n",
      "Loading image from dataset\\Jaideep_001\\24.jpg\n",
      "Loading image from dataset\\Jaideep_001\\25.jpg\n",
      "Loading image from dataset\\Jaideep_001\\26.jpg\n",
      "Loading image from dataset\\Jaideep_001\\27.jpg\n",
      "Loading image from dataset\\Jaideep_001\\28.jpg\n",
      "Loading image from dataset\\Jaideep_001\\29.jpg\n",
      "Loading image from dataset\\Jaideep_001\\3.jpg\n",
      "Loading image from dataset\\Jaideep_001\\30.jpg\n",
      "Loading image from dataset\\Jaideep_001\\31.jpg\n",
      "Loading image from dataset\\Jaideep_001\\32.jpg\n",
      "Loading image from dataset\\Jaideep_001\\33.jpg\n",
      "Loading image from dataset\\Jaideep_001\\34.jpg\n",
      "Loading image from dataset\\Jaideep_001\\35.jpg\n",
      "Loading image from dataset\\Jaideep_001\\36.jpg\n",
      "Loading image from dataset\\Jaideep_001\\37.jpg\n",
      "Loading image from dataset\\Jaideep_001\\38.jpg\n",
      "Loading image from dataset\\Jaideep_001\\39.jpg\n",
      "Loading image from dataset\\Jaideep_001\\4.jpg\n",
      "Loading image from dataset\\Jaideep_001\\40.jpg\n",
      "Loading image from dataset\\Jaideep_001\\41.jpg\n",
      "Loading image from dataset\\Jaideep_001\\42.jpg\n",
      "Loading image from dataset\\Jaideep_001\\43.jpg\n",
      "Loading image from dataset\\Jaideep_001\\44.jpg\n",
      "Loading image from dataset\\Jaideep_001\\45.jpg\n",
      "Loading image from dataset\\Jaideep_001\\46.jpg\n",
      "Loading image from dataset\\Jaideep_001\\47.jpg\n",
      "Loading image from dataset\\Jaideep_001\\48.jpg\n",
      "Loading image from dataset\\Jaideep_001\\49.jpg\n",
      "Loading image from dataset\\Jaideep_001\\5.jpg\n",
      "Loading image from dataset\\Jaideep_001\\6.jpg\n",
      "Loading image from dataset\\Jaideep_001\\7.jpg\n",
      "Loading image from dataset\\Jaideep_001\\8.jpg\n",
      "Loading image from dataset\\Jaideep_001\\9.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\0.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\1.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\10.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\11.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\12.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\13.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\14.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\15.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\16.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\17.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\18.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\19.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\2.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\20.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\21.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\22.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\23.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\24.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\25.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\26.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\27.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\28.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\29.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\3.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\30.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\31.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\32.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\33.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\34.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\35.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\36.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\37.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\38.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\39.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\4.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\40.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\41.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\42.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\43.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\44.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\45.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\46.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\47.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\48.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\49.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\5.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\6.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\7.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\8.jpg\n",
      "Loading image from dataset\\JohnDoe_001\\9.jpg\n"
     ]
    }
   ],
   "source": [
    "create_dataset(user_id=\"001\", name=\"Jaideep\")\n",
    "train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ca1f8a-1f43-4bd2-8629-0076d5435cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognize_and_mark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba39e39-e5b3-43fb-be09-6467b9dac464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
